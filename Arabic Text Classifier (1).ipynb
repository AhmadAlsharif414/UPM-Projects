{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f228da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Dataset\n",
    "file_path = 'filtered_dataset_filtered.xls'  # Update this with your actual file path\n",
    "data = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Clean Text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)  # Keep Arabic and spaces only\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "data['Cleaned_Title'] = data['Title'].apply(clean_text)\n",
    "\n",
    "# Encode Categories\n",
    "label_encoder = LabelEncoder()\n",
    "data['Category_Label'] = label_encoder.fit_transform(data['Category'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2), stop_words=None)\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Title'])\n",
    "y = data['Category_Label']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3bd088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6981132075471698\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.55      0.64      0.59        28\n",
      "       رياضه       0.92      0.85      0.88        27\n",
      "       سياحة       0.67      0.85      0.75        26\n",
      "       سياسه       0.73      0.44      0.55        25\n",
      "\n",
      "    accuracy                           0.70       106\n",
      "   macro avg       0.72      0.70      0.69       106\n",
      "weighted avg       0.71      0.70      0.69       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Naive Bayes\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "report_nb = classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Naive Bayes Classification Report:\\n\", report_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7501ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6792452830188679\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.61      0.68      0.64        28\n",
      "       رياضه       0.81      0.81      0.81        27\n",
      "       سياحة       0.64      0.69      0.67        26\n",
      "       سياسه       0.65      0.52      0.58        25\n",
      "\n",
      "    accuracy                           0.68       106\n",
      "   macro avg       0.68      0.68      0.68       106\n",
      "weighted avg       0.68      0.68      0.68       106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Train SVM\n",
    "svm_classifier = LinearSVC(random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff1a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.4811320754716981\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.43      0.43      0.43        28\n",
      "       رياضه       0.75      0.67      0.71        27\n",
      "       سياحة       0.35      0.58      0.43        26\n",
      "       سياسه       0.55      0.24      0.33        25\n",
      "\n",
      "    accuracy                           0.48       106\n",
      "   macro avg       0.52      0.48      0.48       106\n",
      "weighted avg       0.52      0.48      0.48       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "report_dt = classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree Classification Report:\\n\", report_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e513d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Tuned) Accuracy: 0.5849056603773585\n",
      "Random Forest (Tuned) Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.48      0.43      0.45        28\n",
      "       رياضه       0.87      0.74      0.80        27\n",
      "       سياحة       0.54      0.73      0.62        26\n",
      "       سياسه       0.48      0.44      0.46        25\n",
      "\n",
      "    accuracy                           0.58       106\n",
      "   macro avg       0.59      0.59      0.58       106\n",
      "weighted avg       0.59      0.58      0.58       106\n",
      "\n",
      "Gradient Boosting (Tuned) Accuracy: 0.6037735849056604\n",
      "Gradient Boosting (Tuned) Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.58      0.54      0.56        28\n",
      "       رياضه       0.87      0.74      0.80        27\n",
      "       سياحة       0.55      0.62      0.58        26\n",
      "       سياسه       0.46      0.52      0.49        25\n",
      "\n",
      "    accuracy                           0.60       106\n",
      "   macro avg       0.62      0.60      0.61       106\n",
      "weighted avg       0.62      0.60      0.61       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load Dataset\n",
    "file_path = 'filtered_dataset_filtered.xls'  # Replace with your file path\n",
    "data = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Clean Text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)  # Keep Arabic and spaces only\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "data['Cleaned_Title'] = data['Title'].apply(clean_text)\n",
    "\n",
    "# Encode Categories\n",
    "label_encoder = LabelEncoder()\n",
    "data['Category_Label'] = label_encoder.fit_transform(data['Category'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2), stop_words=None)\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Title'])\n",
    "y = data['Category_Label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Parameter grids for tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf_tuned = best_rf.predict(X_test)\n",
    "accuracy_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)\n",
    "report_rf_tuned = classification_report(y_test, y_pred_rf_tuned, target_names=label_encoder.classes_)\n",
    "\n",
    "# Gradient Boosting\n",
    "grid_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gb, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "best_gb = grid_gb.best_estimator_\n",
    "y_pred_gb_tuned = best_gb.predict(X_test)\n",
    "accuracy_gb_tuned = accuracy_score(y_test, y_pred_gb_tuned)\n",
    "report_gb_tuned = classification_report(y_test, y_pred_gb_tuned, target_names=label_encoder.classes_)\n",
    "\n",
    "# Results\n",
    "print(\"Random Forest (Tuned) Accuracy:\", accuracy_rf_tuned)\n",
    "print(\"Random Forest (Tuned) Report:\\n\", report_rf_tuned)\n",
    "print(\"Gradient Boosting (Tuned) Accuracy:\", accuracy_gb_tuned)\n",
    "print(\"Gradient Boosting (Tuned) Report:\\n\", report_gb_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37b4cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11/11 [==============================] - 1s 22ms/step - loss: 1.3471 - accuracy: 0.3780 - val_loss: 1.2784 - val_accuracy: 0.5176\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.1808 - accuracy: 0.5863 - val_loss: 1.1611 - val_accuracy: 0.5765\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9697 - accuracy: 0.7679 - val_loss: 1.0078 - val_accuracy: 0.6824\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7536 - accuracy: 0.8661 - val_loss: 0.8942 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.9256 - val_loss: 0.7882 - val_accuracy: 0.7059\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3756 - accuracy: 0.9464 - val_loss: 0.7128 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2496 - accuracy: 0.9643 - val_loss: 0.6603 - val_accuracy: 0.7529\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1511 - accuracy: 0.9970 - val_loss: 0.6388 - val_accuracy: 0.7765\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.7529\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9940 - val_loss: 0.6218 - val_accuracy: 0.7647\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.7453\n",
      "Test Loss: 0.6839859485626221\n",
      "Test Accuracy: 0.7452830076217651\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load Dataset\n",
    "file_path = 'filtered_dataset_filtered.xls'  # Replace with your file path\n",
    "data = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Preprocessing: Remove diacritics\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\" ّ|َ|ً|ُ|ٌ|ِ|ٍ|ْ|ـ \"\"\", re.VERBOSE)\n",
    "    return re.sub(arabic_diacritics, '', text)\n",
    "\n",
    "data['Cleaned_Title'] = data['Title'].apply(remove_diacritics)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['Cleaned_Title'])\n",
    "sequences = tokenizer.texts_to_sequences(data['Cleaned_Title'])\n",
    "\n",
    "# Padding sequences\n",
    "max_len = 100  # Maximum sequence length\n",
    "X_padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Load pretrained FastText embeddings using gensim\n",
    "embedding_file = 'cc.ar.300.vec'  # Replace with your downloaded embeddings file path\n",
    "embedding_index = KeyedVectors.load_word2vec_format(embedding_file, binary=False)\n",
    "\n",
    "# Create Embedding Matrix\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Including zero for padding\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embedding_index:\n",
    "        embedding_matrix[i] = embedding_index[word]\n",
    "\n",
    "# Encode Categories\n",
    "label_encoder = {category: idx for idx, category in enumerate(data['Category'].unique())}\n",
    "data['Category_Label'] = data['Category'].map(label_encoder)\n",
    "y_one_hot = to_categorical(data['Category_Label'])\n",
    "\n",
    "# Train-test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build CNN Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a66938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       سياسه       0.70      0.62      0.65        26\n",
      "      اقتصاد       0.56      0.75      0.64        24\n",
      "       سياحة       0.80      0.74      0.77        27\n",
      "       رياضه       0.96      0.86      0.91        29\n",
      "\n",
      "    accuracy                           0.75       106\n",
      "   macro avg       0.75      0.74      0.74       106\n",
      "weighted avg       0.76      0.75      0.75       106\n",
      "\n",
      "Accuracy: 0.7453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions from the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to their class indices\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.keys()))\n",
    "\n",
    "# Optionally, print accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8c1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text to classify (or type 'exit' to quit): انهيار الليرة أبرز التداعيات الاقتصادية على سكان دمشق\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Predicted Category: اقتصاد\n",
      "Enter a text to classify (or type 'exit' to quit): تعرف على عمليات الاحتيال المالي عند السفر\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted Category: سياحة\n",
      "Enter a text to classify (or type 'exit' to quit): مدينة ألمانية في أحضان رومانية\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Category: سياحة\n",
      "Enter a text to classify (or type 'exit' to quit): نتائج قرعة كأس العالم للأندية لكرة القدم 2025\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted Category: رياضه\n",
      "Enter a text to classify (or type 'exit' to quit): خطة نجوم مانشستر سيتي لمواجهة الشكوك والانتقادات\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted Category: رياضه\n",
      "Enter a text to classify (or type 'exit' to quit): هل ساهم تغيّر خطاب هيئة تحرير الشام في نتائج \"ردع العدوان\"؟\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted Category: اقتصاد\n",
      "Enter a text to classify (or type 'exit' to quit): بوليتيكو: 4 حالات عفو رئاسية أكثر إثارة للجدل من عفو بايدن\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Category: اقتصاد\n",
      "Enter a text to classify (or type 'exit' to quit): دعوة لبايدن بمنتدى \"أسبن\" للاعتراف بدولة فلسطين قبل بدء حكم ترامب\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted Category: سياسه\n",
      "Enter a text to classify (or type 'exit' to quit): 172 عاما على \"المحرقة\".. بلدية باريس تقر بجريمة فرنسا بالأغواط الجزائرية\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted Category: سياحة\n",
      "Enter a text to classify (or type 'exit' to quit): كيف ستدير المعارضة السورية المسلحة مدينة حلب؟\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Predicted Category: سياحة\n",
      "Enter a text to classify (or type 'exit' to quit): خبراء: مقاطع فيديو الجنود الإسرائيليين أدلة على انتهاكات القانون الدولي\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted Category: اقتصاد\n",
      "Enter a text to classify (or type 'exit' to quit): غزة دفعت الإسرائيليين في وادي السيليكون للخروج من عزلتهم\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted Category: سياسه\n",
      "Enter a text to classify (or type 'exit' to quit): exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess user input by removing diacritics and tokenizing the text.\n",
    "    \"\"\"\n",
    "    # Remove diacritics\n",
    "    def remove_diacritics(text):\n",
    "        arabic_diacritics = re.compile(\"\"\" ّ|َ|ً|ُ|ٌ|ِ|ٍ|ْ|ـ \"\"\", re.VERBOSE)\n",
    "        return re.sub(arabic_diacritics, '', text)\n",
    "\n",
    "    text = remove_diacritics(text)\n",
    "    \n",
    "    # Tokenize and pad the input text\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "    return padded_sequence\n",
    "\n",
    "def predict_category(input_text):\n",
    "    \"\"\"\n",
    "    Predict the category of the user-entered text.\n",
    "    \"\"\"\n",
    "    # Preprocess the input text\n",
    "    processed_text = preprocess_input_text(input_text)\n",
    "    \n",
    "    # Get model predictions\n",
    "    prediction = model.predict(processed_text)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    # Map the class index back to the category name\n",
    "    category_name = list(label_encoder.keys())[list(label_encoder.values()).index(predicted_class)]\n",
    "    return category_name\n",
    "\n",
    "# Interactive loop for user input\n",
    "while True:\n",
    "    user_input = input(\"Enter a text to classify (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    predicted_category = predict_category(user_input)\n",
    "    print(f\"Predicted Category: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12d2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5776f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f369f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
